{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\n\nfrom wand.image import Image as Img\nImg(filename='../input/cityofla/CityofLA/Additional data/PDFs/2017/february 2017/RATES MANAGER 5601 REVISED.pdf', resolution=300)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport os\nimport numpy as np\nfrom datetime import datetime\nfrom collections  import Counter\nfrom nltk import word_tokenize\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport calendar\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nprint(os.listdir(\"../input\"))\nfrom gensim.models import word2vec\nfrom sklearn.manifold import TSNE\nfrom nltk import pos_tag\nfrom nltk.help import upenn_tagset\nimport gensim\nimport matplotlib.colors as mcolors\nfrom nltk import jaccard_distance\nfrom nltk import ngrams\n#import textstat\nplt.style.use('ggplot')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# job descriptions that are in the format of the text files\n# additional data which is in the format of pdf and images\nbulletins=os.listdir(\"../input/cityofla/CityofLA/Job Bulletins/\")\nadditional=os.listdir(\"../input/cityofla/CityofLA/Additional data/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking all the subsdaries\nfiles=[dir for dir in os.walk('../input/cityofla')]\nfor file in files:\n    print(os.listdir(file[0]))\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvfiles=[]\nfor file in additional:\n    if file.endswith('.csv'):\n        print(file)\n        csvfiles.append(\"../input/cityofla/CityofLA/Additional data/\"+file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(csvfiles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"job_titles = csvfiles[0]\njob_titles = pd.read_csv(job_titles)\nprint(\"The number of rows are %d and columns are %d\"%(job_titles.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(job_titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"job_sample_class = csvfiles[1]\njob_sample_class = pd.read_csv(job_sample_class)\nprint(\"The number of rows are %d and columns are %d\"%(job_sample_class.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"job_sample_class.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_data_dictionary = csvfiles[2]\nkaggle_data_dictionary = pd.read_csv(kaggle_data_dictionary)\nprint(\"The number of rows are %d and columns are %d\"%(kaggle_data_dictionary.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_data_dictionary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's checkout how many files are there in our bulletins\nprint(\"There are about %d files in our bulletins\"%len(bulletins))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code taken from https://www.kaggle.com/shahules/discovering-opportunities-at-la\ndef get_headings(bulletin):       \n    \n    \"\"\"\"function to get the headings from text file\n        takes a single argument\n        1.takes single argument list of bulletin files\"\"\"\n    \n    with open(\"../input/cityofla/CityofLA/Job Bulletins/\"+bulletins[bulletin]) as f:    ##reading text files \n        data=f.read().replace('\\t','').split('\\n')\n        data=[head for head in data if head.isupper()]\n        return data\n        \ndef clean_text(bulletin):      \n    \n    \n    \"\"\"function to do basic data cleaning\n        takes a single argument\n        1.takes single argument list of bulletin files\"\"\"\n                                            \n    \n    with open(\"../input/cityofla/CityofLA/Job Bulletins/\"+bulletins[bulletin]) as f:\n        data=f.read().replace('\\t','').replace('\\n','')\n        return data\n    \n     \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets read file \nwith open('../input/cityofla/CityofLA/Job Bulletins/SENIOR HOUSING INSPECTOR 4244 042718.txt','r') as f:\n    data = f.read()\n    print(data)\n    f.close()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_headings(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_headings(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_dataframe(num,df):\n    \"\"\"\"function to extract features from job bulletin text files and convert to\n    pandas dataframe.\n    function take two arguments \n                        1.the number of files to be read\n                        2.dataframe object                                      \"\"\"\n    \n\n    \n    opendate=re.compile(r'(Open [D,d]ate:)(\\s+)(\\d\\d-\\d\\d-\\d\\d)')       #match open date\n    \n    salary=re.compile(r'\\$(\\d+,\\d+)((\\s(to|and)\\s)(\\$\\d+,\\d+))?')       #match salary\n    \n    requirements=re.compile(r'(REQUIREMENTS?/\\s?MINIMUM QUALIFICATIONS?)(.*)(PROCESS NOTE)')      #match requirements\n    \n    for no in range(0,num):\n        with open(\"../input/cityofla/CityofLA/Job Bulletins/\"+bulletins[no],encoding=\"ISO-8859-1\") as f:         #reading files \n                try:\n                    file=f.read().replace('\\t','')\n                    data=file.replace('\\n','')\n                    headings=[heading for heading in file.split('\\n') if heading.isupper()]             ##getting heading from job bulletin\n\n                    sal=re.search(salary,data)\n                    date=datetime.strptime(re.search(opendate,data).group(3),'%m-%d-%y')\n                    try:\n                        req=re.search(requirements,data).group(2)\n                    except Exception as e:\n                        req=re.search('(.*)NOTES?',re.findall(r'(REQUIREMENTS?)(.*)(NOTES?)',\n                                                              data)[0][1][:1200]).group(1)\n                    \n                    duties=re.search(r'(DUTIES)(.*)(REQ[A-Z])',data).group(2)\n                    try:\n                        enddate=re.search(\n                                r'(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\\s(\\d{1,2},\\s\\d{4})'\n                                ,data).group()\n                    except Exception as e:\n                        enddate=np.nan\n                    \n                    selection= [z[0] for z in re.findall('([A-Z][a-z]+)((\\s\\.\\s)+)',data)]     ##match selection criteria\n                    \n                    df=df.append({'File Name':bulletins[no],'Position':headings[0].lower(),'salary_start':sal.group(1),\n                               'salary_end':sal.group(5),\"opendate\":date,\"requirements\":req,'duties':duties,\n                                'deadline':enddate,'selection':selection},ignore_index=True)\n                    \n                    \n                    reg=re.compile(r'(One|Two|Three|Four|Five|Six|Seven|Eight|Nine|Ten|one|two|three|four)\\s(years?)\\s(of\\sfull(-|\\s)time)')\n                    df['EXPERIENCE_LENGTH']=df['requirements'].apply(lambda x :  re.search(reg,x).group(1) if re.search(reg,x) is not None  else np.nan)\n                    df['FULL_TIME_PART_TIME']=df['EXPERIENCE_LENGTH'].apply(lambda x:  'FULL_TIME' if x is not np.nan else np.nan )\n                    \n                    reg=re.compile(r'(One|Two|Three|Four|Five|Six|Seven|Eight|Nine|Ten|one|two|three|four)(\\s|-)(years?)\\s(college)')\n                    df['EDUCATION_YEARS']=df['requirements'].apply(lambda x :  re.search(reg,x).group(1) if re.search(reg,x) is not None  else np.nan)\n                    df['SCHOOL_TYPE']=df['EDUCATION_YEARS'].apply(lambda x : 'College or University' if x is not np.nan else np.nan)\n                    \n                except Exception as e:\n                    print('umatched sequence')\n                    \n                    \n                \n                \n        \n           \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(columns=['File Name','Position','salary_start','salary_end','opendate','requirements','duties','deadline'])\ndf=to_dataframe(len(bulletins),df)\ndf.to_csv('job class output.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndata_dictionary=pd.DataFrame({'Field Name':['File Name','Position','salary_start','salary_end','opendate',\n                                            'requirements','duties','deadline','selection','EXPERIENCE_LENGTH','FULL_TIME_PART_TIME','EDUCATION_YEARS','SCHOOL_TYPE'],\n                             })\n\ndata_dictionary['Description']=['The file name of the job bulletin from which each record came','The title of the particular class (e.g., Systems Analyst, Carpenter)',\n                              'The overall salary start','The overall maximum salary','The date the job bulletin opened','Overall requirement that has to be filled',\n                              'A summary of what someone does in the particular job\\n','The date the job bulletin closed','list of selection criterias','Years required in a particular job class or external role.',\n                              'Whether the required experience is full-time, part','Years required in a particular education program',\n                               'School Type: School type required (e.g. college or university, high school)']\n\ndata_dictionary['Data Type']=['string']*13\n\ndata_dictionary['Accepts Null Values?']=['Yes']*13\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dictionary.to_csv('data dictionary.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are %d different jobs available' %df['Position'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\ntext=''.join(job for job in df['Position'])                                ##joining  data to form text\ntext=word_tokenize(text)\njobs=Counter(text)                                                         ##counting number of occurences\njobs_class=[job for job in jobs.most_common(12) if len(job[0])>3]          ##selecting most common words\nprint(jobs_class)\n#offers=[job[1] for job in jobs.most_common(12) if len(job[0]>3)]\na,b=map(list, zip(*jobs_class))\nprint(a)\nprint(b)\nsns.barplot(b,a,palette='rocket')                                           ##creating barplot\nplt.title('Job sectors')\nplt.xlabel(\"count\")\nplt.ylabel('sector')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\"\n    convert salary to proper  form \n    by removing '$' and ',' symbols.\n                                    \"\"\"\n\ndf['salary_start']=[int(sal.split(',')[0]+sal.split(',')[1] ) for sal in df['salary_start']]   \ndf['salary_end']=[sal.replace('$','')  if sal!= None else 0 for sal in df['salary_end']  ]\ndf['salary_end']=[int(sal.split(',')[0]+sal.split(',')[1] ) if type(sal)!=int else 0 for sal in df['salary_end']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nsns.distplot(df['salary_start'])\nplt.title('salary distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''finding the most paid 10 jobs at LA'''\n\nmost_paid=df[['Position','salary_start']].sort_values(by='salary_start',ascending=False)[:10]\nplt.figure(figsize=(7,5))\nsns.barplot(y=most_paid['Position'],x=most_paid['salary_start'],palette='rocket')\nplt.title('Best paid jobs in LA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"''''calculating salary start - salary end '''\n\ndf['salary_diff']=abs(df['salary_start']-df['salary_end'])\n\nranges=df[['Position','salary_diff']].sort_values(by='salary_diff',ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nsns.barplot(y=ranges['Position'],x=ranges['salary_diff'],palette='RdBu')   ##plotting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ranges","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"experience=df['EXPERIENCE_LENGTH'].value_counts().reset_index()\nexperience['index']=experience['index'].apply(lambda x : x.lower())\nexperience=experience.groupby('index',as_index=False).agg('sum')\nlabels=experience['index']\nsizes=experience['EXPERIENCE_LENGTH']\nplt.figure(figsize=(5,7))\nplt.pie(sizes,explode=(0, 0.1, 0, 0,0,0,0),labels=labels)\nplt.gca().axis('equal')\nplt.title('Experience value count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Extracting year out of opendate timestamp object and counting\n    the number of each occurence of each year using count_values() '''\n\ndf['year_of_open']=[date.year for date in df['opendate']]\n\ncount=df['year_of_open'].value_counts(ascending=True)\nyears=['2020','2019','2018', '2017', '2016', '2015', '2014', '2013', '2012', '2008', '2006',\n           '2005', '2002', '1999']\nplt.figure(figsize=(7,5))\nplt.plot([z for z in reversed(years)],count.values,color='blue')\n\nplt.title('Oppurtunities over years')\nplt.xlabel('years')\nplt.ylabel('count')\nplt.gca().set_xticklabels([z for z in reversed(years)],rotation='45')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}